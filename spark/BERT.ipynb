{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe5dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spark-nlp==3.3.4\n",
      "  Downloading https://files.pythonhosted.org/packages/48/8c/0d83c7e606651d0bec6c8c9a03bf3acbe1d9fbf8f840aa115505222e6328/spark_nlp-3.3.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-3.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spark-nlp==3.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7eaaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-4-136.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f85c885b128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef179b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.4MB 98kB/s  eta 0:00:01  4% |â–ˆâ–‹                              | 665kB 36.2MB/s eta 0:00:01    32% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 4.3MB 36.2MB/s eta 0:00:01    58% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 7.8MB 37.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.5MB 142kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/ea/84c7247f5c96c5a1b619fe822fb44052081ccfbe487a49d4c888306adec7/nltk-3.6.7-py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 921kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/e3/d9f046b5d1c94a3aeab15f1f867aa414f8ee9d196fae6865f1d6a0ee1a0b/pytz-2021.3-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 2.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/57/277ac1dc8b7e49f48c6fb74929dd32d27ea5e3c504a766f4420d28a673ef/regex-2021.11.10-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (670kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675kB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/d5/0163eb0cfa0b673aa4fe1cd3ea9d8a81ea0f32e50807b0c295871e4aab2e/joblib-1.1.0-py2.py3-none-any.whl (306kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307kB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/63/f3/b7a1b8e40fd1bd049a34566eb353527bb9b8e9b98f8b6cf803bb64d8ce95/tqdm-4.62.3-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas)\n",
      "Installing collected packages: numpy, pytz, pandas, regex, joblib, tqdm, nltk\n",
      "Successfully installed joblib-1.1.0 nltk-3.6.7 numpy-1.19.5 pandas-1.1.5 pytz-2021.3 regex-2021.11.10 tqdm-4.62.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d457c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c083b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.ml.feature import Tokenizer as pysparkTokenizer, HashingTF, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner, PerceptronModel, Chunker\n",
    "from pyspark.ml.clustering import LDA\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sparknlp\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6c7b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 3.3.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5e568",
   "metadata": {},
   "source": [
    "## Preprocess tweeter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc287bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|                text|          user|\n",
      "+--------------------+--------------+\n",
      "| You really like ...|   TomCottonAR|\n",
      "| ...eyes off you ...|   TomCottonAR|\n",
      "| ...taxes for you...|   TomCottonAR|\n",
      "|This is a very tr...|       tedcruz|\n",
      "|_JoeManchin I app...|           Sen|\n",
      "| - Nearly 1 Milli...|         POTUS|\n",
      "|_JoeManchin is gi...|           Sen|\n",
      "| Big Pharma compa...|  amyklobuchar|\n",
      "| didn't he lie an...|HillaryClinton|\n",
      "| The Name Ray Epp...|HillaryClinton|\n",
      "|There is somethin...|  amyklobuchar|\n",
      "|I know folks are ...|         POTUS|\n",
      "|                  ðŸ‘€|       tedcruz|\n",
      "|This is a very tr...|       tedcruz|\n",
      "|A son of Searchli...|         POTUS|\n",
      "|In honor of forme...|    SenSchumer|\n",
      "|_JoeManchin Where...|           Sen|\n",
      "| https://t.co/qvR...|      RandPaul|\n",
      "| https://t.co/9kC...|      RandPaul|\n",
      "| Republicans cons...|      HouseGOP|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lenght: 14169'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet = spark.read.option(\"tableName\", \"Tweets\").format(\"dynamodb\").load().select(f.col(\"text\"))\n",
    "df_tweet = df_tweet.withColumn(\"user\", regexp_extract(col(\"text\"), r\"@([A-Za-z0-9]+)\", 1))\n",
    "df_tweet = (df_tweet.withColumn('text', regexp_replace('text', r\"@[A-Za-z0-9]+\", ''))\n",
    "            .withColumn('text', regexp_replace('text', \"RT[\\s:]+\", '')))\n",
    "df_tweet.show()\n",
    "f\"Lenght: {df_tweet.count()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58b2da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|party|       username|\n",
      "+-----+---------------+\n",
      "|    D|  SenWhitehouse|\n",
      "|    D| SenCoonsOffice|\n",
      "|    R|     ThomTillis|\n",
      "|    D|    SenStabenow|\n",
      "|    R|RoundsforSenate|\n",
      "|    D|       timkaine|\n",
      "|    D|    SenJackReed|\n",
      "|    R|  JohnnyIsakson|\n",
      "|    D|      SenBooker|\n",
      "|    R|  SenJohnHoeven|\n",
      "|    R|  TheBushCenter|\n",
      "|    R|RepublicanStudy|\n",
      "|    R|SenatorLankford|\n",
      "|    D| SenJeffMerkley|\n",
      "|    D| MurrayCampaign|\n",
      "|    R|   SenTomCotton|\n",
      "|    R|     TeamCornyn|\n",
      "|    R|    RogerWicker|\n",
      "|    D|      Bob_Casey|\n",
      "|    R|    TomCottonAR|\n",
      "+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lenght: 198'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc = spark.read.option(\"header\",\"true\").csv(\"../accounts.csv\").select(\"party\", \"username\").distinct()\n",
    "df_acc.show()\n",
    "f\"Lenght: {df_acc.count()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e514a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|party|                text|\n",
      "+-----+--------------------+\n",
      "|    R| You really like ...|\n",
      "|    R| ...eyes off you ...|\n",
      "|    R| ...taxes for you...|\n",
      "|    R|This is a very tr...|\n",
      "|    D| - Nearly 1 Milli...|\n",
      "|    D| Big Pharma compa...|\n",
      "|    D| didn't he lie an...|\n",
      "|    D| The Name Ray Epp...|\n",
      "|    D|There is somethin...|\n",
      "|    D|I know folks are ...|\n",
      "|    R|                  ðŸ‘€|\n",
      "|    R|This is a very tr...|\n",
      "|    D|A son of Searchli...|\n",
      "|    D|In honor of forme...|\n",
      "|    R| https://t.co/qvR...|\n",
      "|    R| https://t.co/9kC...|\n",
      "|    R| Republicans cons...|\n",
      "|    R|How to steal an e...|\n",
      "|    D| A day after Pres...|\n",
      "|    D| F**k.  Off. http...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tweet = df_tweet.join(df_acc, df_tweet.user == df_acc.username).select('party', 'text')\n",
    "df_tweet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058b4f7",
   "metadata": {},
   "source": [
    "## Preprocess reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d319b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|party|                text|\n",
      "+-----+--------------------+\n",
      "|    D|Lincoln County lo...|\n",
      "|    D|Harris charts her...|\n",
      "|    D|Rudy Giuliani and...|\n",
      "|    D|Thousands of Russ...|\n",
      "|    D|A Capitol rioter ...|\n",
      "|    D|19-year-old charg...|\n",
      "|    D|Harris says Ameri...|\n",
      "|    D|Harris says Ameri...|\n",
      "|    D|America is now in...|\n",
      "|    D|Alleged â€˜deadâ€™ Ge...|\n",
      "|    D|America is now in...|\n",
      "|    D|Alleged â€˜deadâ€™ Ge...|\n",
      "|    D|#TBT: The First K...|\n",
      "|    D|#TBT: The First K...|\n",
      "|    D|Joe Biden's admin...|\n",
      "|    D|Joe Biden's admin...|\n",
      "|    D|Georgia Republica...|\n",
      "|    D|What Commitment t...|\n",
      "|    D|Supreme Court: Ju...|\n",
      "|    D|Georgia Republica...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lenght: 178'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit = spark.read.option(\"tableName\", \"RedditPosts\").format(\"dynamodb\").load().select(f.col(\"submission_id\").alias(\"text\"), f.col(\"subreddit\"))\n",
    "df_reddit = df_reddit.withColumn(\"party\", initcap(col('subreddit')).substr(1,1)).select(\"party\", \"text\")\n",
    "df_reddit.show()\n",
    "f\"Lenght: {df_reddit.count()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9fd48",
   "metadata": {},
   "source": [
    "## Join both sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a09b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|party|                text|\n",
      "+-----+--------------------+\n",
      "|    R| You really like ...|\n",
      "|    R| ...eyes off you ...|\n",
      "|    R| ...taxes for you...|\n",
      "|    R|This is a very tr...|\n",
      "|    D| - Nearly 1 Milli...|\n",
      "|    D| Big Pharma compa...|\n",
      "|    D| didn't he lie an...|\n",
      "|    D| The Name Ray Epp...|\n",
      "|    D|There is somethin...|\n",
      "|    D|I know folks are ...|\n",
      "|    R|                  ðŸ‘€|\n",
      "|    R|This is a very tr...|\n",
      "|    D|A son of Searchli...|\n",
      "|    D|In honor of forme...|\n",
      "|    R| https://t.co/qvR...|\n",
      "|    R| https://t.co/9kC...|\n",
      "|    R| Republicans cons...|\n",
      "|    R|How to steal an e...|\n",
      "|    D| A day after Pres...|\n",
      "|    D| F**k.  Off. http...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lenght: 1178'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_tweet.limit(1000).union(df_reddit)\n",
    "df.show()\n",
    "f\"Lenght: {df.count()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f954f0f",
   "metadata": {},
   "source": [
    "## Train test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2711cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332e1f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|party|count|\n",
      "+-----+-----+\n",
      "|    D|  539|\n",
      "|    R|  330|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy(\"party\") \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64909a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|party|count|\n",
      "+-----+-----+\n",
      "|    D|  198|\n",
      "|    R|  111|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy(\"party\") \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1bf94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aafe921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_small_bert_L8_512 download started this may take some time.\n",
      "Approximate size to download 149.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embeddings = BertSentenceEmbeddings.pretrained(\"sent_small_bert_L8_512\") \\\n",
    "      .setInputCols(\"document\") \\\n",
    "      .setOutputCol(\"sentence_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2ce623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_sent = BertSentenceEmbeddings.pretrained('sent_small_bert_L8_512')\\\n",
    "#     .setInputCols( [\"document\"])\\\n",
    "#     .setOutputCol(\"sentence_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea3092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classes/labels/categories are in category column\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols ([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"party\")\\\n",
    "    .setMaxEpochs (20)\\\n",
    "    .setEnableOutputLogs (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd7449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sent_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document\n",
    "        #embeddings,\n",
    "        #classsifierdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_Model = bert_sent_clf_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bert_Model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e68c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
