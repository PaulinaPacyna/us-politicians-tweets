{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c103e12",
   "metadata": {},
   "source": [
    "# 0. Libraries and spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a9b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==3.3.4 in /usr/local/lib/python3.6/dist-packages\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spark-nlp==3.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32acb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.6/dist-packages (from nltk)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da483f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-11-226.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7eff2a7067b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"4G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.4\")\\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5ac11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import LemmatizerModel\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer as pysparkTokenizer, HashingTF, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner, PerceptronModel, Chunker\n",
    "from pyspark.ml.clustering import LDA\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7fe3c",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d109779f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|extractionTime| geo|                 id|lang|                text|           user|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|    1639926916|null|1472586335487672330|  en|@Sen_JoeManchin ?...|    MikeyOZPK15|\n",
      "|    1639929571|null|1472597472530681860|  en|@Sen_JoeManchin ?...| mindfulliving1|\n",
      "|    1639927432|null|1472588501753503751|  en|RT @TheDemocrats:...|Dshe51arerDiana|\n",
      "|    1639925273|null|1472579445177389059|  en|RT @SenSchumer: I...|MaryPer46923539|\n",
      "|    1639929482|null|1472597099984429056|  en|RT @TheDemocrats:...|  Angelstrenght|\n",
      "|    1639924524|null|1472576304566263808|  en|@SenWarren or Poc...| marinecorp7375|\n",
      "|    1639926337|null|1472583908558573571|  en|RT @TheDemocrats:...|      Diditrek1|\n",
      "|    1639927868|null|1472590328863641606|  en|RT @ChuckGrassley...| MysteryMind117|\n",
      "|    1639927508|null|1472588821019738114|  en|RT @ChuckGrassley...|  DeezInDetroit|\n",
      "|    1639926696|null|1472585412434710536|  en|RT @SenSchumer: I...|      tshequine|\n",
      "|    1639928556|null|1472593213395505152|  en|@JoeBiden Oh and ...|slavadoraIvanov|\n",
      "|    1639924268|null|1472575231084666887|  en|@Sen_JoeManchin T...| SteveB71969175|\n",
      "|    1639925117|null|1472578791495057409|  en|@SenSchumer Shame...| 0NotImportant1|\n",
      "|    1639925407|null|1472580007063175177|  en|@SenTedCruz The R...| OldGuy59872445|\n",
      "|    1639927263|null|1472587789589880834|  en|@tedcruz Safe? Do...|   GarrapataRed|\n",
      "|    1639924563|null|1472576467519393802|  en|@Sen_JoeManchin t...| EnriqueTaylorr|\n",
      "|    1639927977|null|1472590784238997508|  en|@Sen_JoeManchin c...|dkeller82748064|\n",
      "|    1639928446|null|1472592753028579328|  en|@Sen_JoeManchin Y...|stuffedskullcat|\n",
      "|    1639927200|null|1472587527257313282|  en|RT @amyklobuchar:...|Houckadoodledoo|\n",
      "|    1639928921|null|1472594745465528323|  en|@Sen_JoeManchin b...|   ElLeonFierro|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lenght: 12051'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"/home/ubuntu/temp-data\")\n",
    "df.repartition(50).write.mode(\"overwrite\").parquet(\"/home/ubuntu/temp-data2\")\n",
    "df = spark.read.parquet(\"/home/ubuntu/temp-data2\")\n",
    "# df = spark.read.option(\"tableName\", \"tweets\").format(\"dynamodb\").load()\n",
    "df.show()\n",
    "f\"Lenght: {df.count()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308ca20",
   "metadata": {},
   "source": [
    "Removing special chacaters and changing to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c05c398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|extractionTime| geo|                 id|lang|                text|           user|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|    1639926916|null|1472586335487672330|  en|@senjoemanchin on...|    MikeyOZPK15|\n",
      "|    1639929571|null|1472597472530681860|  en|@senjoemanchin  w...| mindfulliving1|\n",
      "|    1639927432|null|1472588501753503751|  en|rt @thedemocrats ...|Dshe51arerDiana|\n",
      "|    1639925273|null|1472579445177389059|  en|rt @senschumer im...|MaryPer46923539|\n",
      "|    1639929482|null|1472597099984429056|  en|rt @thedemocrats ...|  Angelstrenght|\n",
      "|    1639924524|null|1472576304566263808|  en|@senwarren or poc...| marinecorp7375|\n",
      "|    1639926337|null|1472583908558573571|  en|rt @thedemocrats ...|      Diditrek1|\n",
      "|    1639927868|null|1472590328863641606|  en|rt @chuckgrassley...| MysteryMind117|\n",
      "|    1639927508|null|1472588821019738114|  en|rt @chuckgrassley...|  DeezInDetroit|\n",
      "|    1639926696|null|1472585412434710536|  en|rt @senschumer im...|      tshequine|\n",
      "|    1639928556|null|1472593213395505152|  en|@joebiden oh and ...|slavadoraIvanov|\n",
      "|    1639924268|null|1472575231084666887|  en|@senjoemanchin th...| SteveB71969175|\n",
      "|    1639925117|null|1472578791495057409|  en|@senschumer shame...| 0NotImportant1|\n",
      "|    1639925407|null|1472580007063175177|  en|@sentedcruz the r...| OldGuy59872445|\n",
      "|    1639927263|null|1472587789589880834|  en|@tedcruz safe don...|   GarrapataRed|\n",
      "|    1639924563|null|1472576467519393802|  en|@senjoemanchin th...| EnriqueTaylorr|\n",
      "|    1639927977|null|1472590784238997508|  en|@senjoemanchin co...|dkeller82748064|\n",
      "|    1639928446|null|1472592753028579328|  en|@senjoemanchin yo...|stuffedskullcat|\n",
      "|    1639927200|null|1472587527257313282|  en|rt @amyklobuchar ...|Houckadoodledoo|\n",
      "|    1639928921|null|1472594745465528323|  en|@senjoemanchin be...|   ElLeonFierro|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"text\", f.lower(f.regexp_replace(f.col(\"text\"), \"[^A-Za-z0-9@ ]\", \"\")))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13867c2a",
   "metadata": {},
   "source": [
    "# 2. LDA - topics analysis - Pyspark only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ece113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----+--------------------+---------------+--------------------+--------------------+\n",
      "|extractionTime| geo|                 id|lang|                text|           user|              tokens|       no stop words|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+--------------------+--------------------+\n",
      "|    1639926916|null|1472586335487672330|  en|@senjoemanchin on...|    MikeyOZPK15|[@senjoemanchin, ...|[@senjoemanchin, ...|\n",
      "|    1639929571|null|1472597472530681860|  en|@senjoemanchin  w...| mindfulliving1|[@senjoemanchin, ...|[@senjoemanchin, ...|\n",
      "|    1639927432|null|1472588501753503751|  en|rt @thedemocrats ...|Dshe51arerDiana|[rt, @thedemocrat...|[rt, @thedemocrat...|\n",
      "|    1639925273|null|1472579445177389059|  en|rt @senschumer im...|MaryPer46923539|[rt, @senschumer,...|[rt, @senschumer,...|\n",
      "|    1639929482|null|1472597099984429056|  en|rt @thedemocrats ...|  Angelstrenght|[rt, @thedemocrat...|[rt, @thedemocrat...|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'extractionTime': 1639926916,\n",
       "  'geo': None,\n",
       "  'id': 1472586335487672330,\n",
       "  'lang': 'en',\n",
       "  'text': '@senjoemanchin only democrat with a set of balls',\n",
       "  'user': 'MikeyOZPK15',\n",
       "  'tokens': ['@senjoemanchin',\n",
       "   'only',\n",
       "   'democrat',\n",
       "   'with',\n",
       "   'a',\n",
       "   'set',\n",
       "   'of',\n",
       "   'balls'],\n",
       "  'no stop words': ['@senjoemanchin', 'democrat', 'set', 'balls']},\n",
       " {'extractionTime': 1639929571,\n",
       "  'geo': None,\n",
       "  'id': 1472597472530681860,\n",
       "  'lang': 'en',\n",
       "  'text': '@senjoemanchin  we thank you  we need you  we will never forget  manofthehour americanhero',\n",
       "  'user': 'mindfulliving1',\n",
       "  'tokens': ['@senjoemanchin',\n",
       "   '',\n",
       "   'we',\n",
       "   'thank',\n",
       "   'you',\n",
       "   '',\n",
       "   'we',\n",
       "   'need',\n",
       "   'you',\n",
       "   '',\n",
       "   'we',\n",
       "   'will',\n",
       "   'never',\n",
       "   'forget',\n",
       "   '',\n",
       "   'manofthehour',\n",
       "   'americanhero'],\n",
       "  'no stop words': ['@senjoemanchin',\n",
       "   '',\n",
       "   'thank',\n",
       "   '',\n",
       "   'need',\n",
       "   '',\n",
       "   'never',\n",
       "   'forget',\n",
       "   '',\n",
       "   'manofthehour',\n",
       "   'americanhero']},\n",
       " {'extractionTime': 1639927432,\n",
       "  'geo': None,\n",
       "  'id': 1472588501753503751,\n",
       "  'lang': 'en',\n",
       "  'text': 'rt @thedemocrats this battles not over we must pass the freedom to vote act and the john lewis voting rights act we must president',\n",
       "  'user': 'Dshe51arerDiana',\n",
       "  'tokens': ['rt',\n",
       "   '@thedemocrats',\n",
       "   'this',\n",
       "   'battles',\n",
       "   'not',\n",
       "   'over',\n",
       "   'we',\n",
       "   'must',\n",
       "   'pass',\n",
       "   'the',\n",
       "   'freedom',\n",
       "   'to',\n",
       "   'vote',\n",
       "   'act',\n",
       "   'and',\n",
       "   'the',\n",
       "   'john',\n",
       "   'lewis',\n",
       "   'voting',\n",
       "   'rights',\n",
       "   'act',\n",
       "   'we',\n",
       "   'must',\n",
       "   'president'],\n",
       "  'no stop words': ['rt',\n",
       "   '@thedemocrats',\n",
       "   'battles',\n",
       "   'must',\n",
       "   'pass',\n",
       "   'freedom',\n",
       "   'vote',\n",
       "   'act',\n",
       "   'john',\n",
       "   'lewis',\n",
       "   'voting',\n",
       "   'rights',\n",
       "   'act',\n",
       "   'must',\n",
       "   'president']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = pysparkTokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopwords_cleaner = StopWordsRemover(inputCol=\"tokens\", outputCol=\"no stop words\")\n",
    "nlp_pipeline = Pipeline(\n",
    "    stages=[tokenizer,\n",
    "            stopwords_cleaner])\n",
    "nlp_model = nlp_pipeline.fit(df)\n",
    "processed_df  = nlp_model.transform(df)\n",
    "processed_df.show(5)\n",
    "processed_df.limit(3).toPandas().to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f0009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@potus', '@senschumer', 'rt', 'president', 'act', 'must', '@thedemocrats', 'voting', 'rights', 'vote', 'pass', '@vp', '@amyklobuchar', 'freedom', 'john'] \n",
      "\n",
      "['', '@tedcruz', 'rt', 'mask', 'party', 'democrat', 'wear', 'must', 'official', 'forever', 'positioneverybody', '@kamalaharris', '@chrismurphyct', 'time', 'last'] \n",
      "\n",
      "['rt', 'back', 'better', 'build', '@kamalaharris', 'senate', 'republicans', 'want', 'going', '@chrismurphyct', 'congress', 'cruz', 'lets', 'lower', 'costs'] \n",
      "\n",
      "['@senjoemanchin', '', 'manchin', '@lindseygrahamsc', 'joe', 'rt', 'bbb', 'people', 'vote', 'senator', 'youre', 'dont', 'republican', 'bill', 'amp'] \n",
      "\n",
      "['@joebiden', 'get', '@senjoemanchin', 'people', 'rt', '@sentedcruz', '@senwarren', 'covid', 'way', 'biden', 'american', 'fox', 'youre', 'think', 'yet'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"no stop words\", outputCol=\"features\", vocabSize=500, minDF=3.0)\n",
    "cv_model = cv.fit(processed_df)\n",
    "lda = LDA(k=5, maxIter=100)\n",
    "model = lda.fit(cv_model.transform(processed_df))\n",
    "for indices in model.describeTopics(15).select(\"termIndices\").rdd.flatMap(lambda x: x).collect():\n",
    "    print([cv_model.vocabulary[i] for i in indices], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00101ca",
   "metadata": {},
   "source": [
    "# 3. LDA - topics analysis - SparkNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00280e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[OK!]\n",
      "+--------------+----+-------------------+----+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|extractionTime| geo|                 id|lang|                text|           user|   finished_unigrams|     finished_ngrams|               final|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|    1639926916|null|1472586335487672330|  en|@senjoemanchin on...|    MikeyOZPK15|[senjoemanchin, d...|[@senjoemanchin o...|[senjoemanchin, d...|\n",
      "|    1639929571|null|1472597472530681860|  en|@senjoemanchin  w...| mindfulliving1|[senjoemanchin, t...|[manofthehour ame...|[senjoemanchin, t...|\n",
      "|    1639927432|null|1472588501753503751|  en|rt @thedemocrats ...|Dshe51arerDiana|[rt, thedemocrats...|[freedom to vote ...|[rt, thedemocrats...|\n",
      "|    1639925273|null|1472579445177389059|  en|rt @senschumer im...|MaryPer46923539|[rt, senschumer, ...|[proud we confirm...|[rt, senschumer, ...|\n",
      "|    1639929482|null|1472597099984429056|  en|rt @thedemocrats ...|  Angelstrenght|[rt, thedemocrats...|[freedom to vote ...|[rt, thedemocrats...|\n",
      "|    1639924524|null|1472576304566263808|  en|@senwarren or poc...| marinecorp7375|[senwarren, pocah...|[corrupt politici...|[senwarren, pocah...|\n",
      "|    1639926337|null|1472583908558573571|  en|rt @thedemocrats ...|      Diditrek1|[rt, thedemocrats...|[freedom to vote ...|[rt, thedemocrats...|\n",
      "|    1639927868|null|1472590328863641606|  en|rt @chuckgrassley...| MysteryMind117|[rt, chuckgrassle...|[dems taxampspend...|[rt, chuckgrassle...|\n",
      "|    1639927508|null|1472588821019738114|  en|rt @chuckgrassley...|  DeezInDetroit|[rt, chuckgrassle...|[dems taxampspend...|[rt, chuckgrassle...|\n",
      "|    1639926696|null|1472585412434710536|  en|rt @senschumer im...|      tshequine|[rt, senschumer, ...|[proud we confirm...|[rt, senschumer, ...|\n",
      "|    1639928556|null|1472593213395505152|  en|@joebiden oh and ...|slavadoraIvanov|[joebiden, oh, fr...|[walter steinemie...|[joebiden, oh, fr...|\n",
      "|    1639924268|null|1472575231084666887|  en|@senjoemanchin th...| SteveB71969175|[senjoemanchin, t...|[strong dont, you...|[senjoemanchin, t...|\n",
      "|    1639925117|null|1472578791495057409|  en|@senschumer shame...| 0NotImportant1|[senschumer, sham...|[manchin in line,...|[senschumer, sham...|\n",
      "|    1639925407|null|1472580007063175177|  en|@sentedcruz the r...| OldGuy59872445|[sentedcruz, radi...|[radical right, s...|[sentedcruz, radi...|\n",
      "|    1639927263|null|1472587789589880834|  en|@tedcruz safe don...|   GarrapataRed|[tedcruz, safe, d...|[safe dont, roose...|[tedcruz, safe, d...|\n",
      "|    1639924563|null|1472576467519393802|  en|@senjoemanchin th...| EnriqueTaylorr|[senjoemanchin, t...|[trillion dollars...|[senjoemanchin, t...|\n",
      "|    1639927977|null|1472590784238997508|  en|@senjoemanchin co...|dkeller82748064|[senjoemanchin, c...|[poorest state, @...|[senjoemanchin, c...|\n",
      "|    1639928446|null|1472592753028579328|  en|@senjoemanchin yo...|stuffedskullcat|[senjoemanchin, s...|[@senjoemanchin y...|[senjoemanchin, s...|\n",
      "|    1639927200|null|1472587527257313282|  en|rt @amyklobuchar ...|Houckadoodledoo|[rt, amyklobuchar...|[best way, covid ...|[rt, amyklobuchar...|\n",
      "|    1639928921|null|1472594745465528323|  en|@senjoemanchin be...|   ElLeonFierro|[senjoemanchin, s...|[stupid sob, good...|[senjoemanchin, s...|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol('document')\n",
    "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('tokenized')\n",
    "normalizer = Normalizer().setInputCols(['tokenized']).setOutputCol('normalized')\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols(['normalized']).setOutputCol('lemmatized')\n",
    "stopwords_cleaner = StopWordsCleaner().setInputCols(['lemmatized'])\\\n",
    ".setOutputCol('unigrams').setStopWords(stopwords.words('english'))\n",
    "pos_tagger = PerceptronModel.pretrained('pos_anc').setInputCols(['document', 'unigrams']).setOutputCol('pos')\n",
    "chunker = Chunker().setInputCols(['document', 'pos']).setOutputCol('ngrams').setRegexParsers(['<JJ>+<NN>', '<NN>+<NN>'])\n",
    "finisher = Finisher().setInputCols(['unigrams', 'ngrams'])\n",
    "pipeline = Pipeline() \\\n",
    "     .setStages([documentAssembler,\n",
    "                 tokenizer,\n",
    "                 normalizer,\n",
    "                 lemmatizer,\n",
    "                 stopwords_cleaner,\n",
    "                 pos_tagger,\n",
    "                 chunker,\n",
    "                 finisher])\n",
    "processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
    "processed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24050e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tedcruz', 'rt', 'mask', 'democrat', 'party', 'wear', 'official', 'must', 'forever', 'positioneverybody', '@tedcruz  this is now the official democrat party positioneverybody', 'kamalaharris', 'well', 'one', 'cost'] \n",
      "\n",
      "['rt', 'potus', 'senschumer', 'covid', 'time', 'amyklobuchar', 'th', 'federal', 'month', 'word', 'good', 'vaccine', 'last', 'school', 'chrismurphyct'] \n",
      "\n",
      "['lindseygrahamsc', 'let', 'senate', 'tell', 'go', 'chrismurphyct', 'rt', 'cruz', 'hold', 'agree', 'stay', 'clear', 'schumer', 'lift', 'session'] \n",
      "\n",
      "['senjoemanchin', 'potus', 'people', 'joebiden', 'youre', 'rt', 'dont', 'one', 'vp', 'get', 'thank', 'manchin', 'american', 'like', 'care'] \n",
      "\n",
      "['senjoemanchin', 'vote', 'right', 'bbb', 'back', 'act', 'well', 'president', 'must', 'rt', 'get', 'joe', 'thedemocrats', 'manchin', 'say'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"final\", outputCol=\"features\", vocabSize=500, minDF=3.0)\n",
    "cv_model = cv.fit(processed_df)\n",
    "lda = LDA(k=5, maxIter=100)\n",
    "model = lda.fit(cv_model.transform(processed_df))\n",
    "for indices in model.describeTopics(15).select(\"termIndices\").rdd.flatMap(lambda x: x).collect():\n",
    "    print([cv_model.vocabulary[i] for i in indices], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356aa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
