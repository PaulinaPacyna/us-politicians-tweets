{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c103e12",
   "metadata": {},
   "source": [
    "# 0. Libraries and spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a9b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==3.3.4 in /usr/local/lib/python3.6/dist-packages\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spark-nlp==3.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32acb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.6/dist-packages (from nltk)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da483f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-7-212.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6d604f6160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"4G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.4\")\\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5ac11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import LemmatizerModel\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer as pysparkTokenizer, HashingTF, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner, PerceptronModel, Chunker\n",
    "from pyspark.ml.clustering import LDA\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7fe3c",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d109779f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|extractionTime| geo|                 id|lang|                text|           user|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|    1640622119|null|1475502230484697094|  en|@POTUS ‚ìò ùó¢ùó≥ùó≥ùó∂...|      rodriQuez|\n",
      "|    1639923135|null|1472570476295860228| und|@VP @RepLowenthal...|  bandarfize1ap|\n",
      "|    1639923254|null|1472570974570795010|  en|@VP @allysonfelix...|   joshycharm01|\n",
      "|    1639927142|null|1472587285225156609|  en|@Sen_JoeManchin w...|        Caz_U_L|\n",
      "|    1640622154|null|1475502374982610946|  en|RT @HouseGOP: Pre...|     CallMeBake|\n",
      "|    1639925917|null|1472582147638796293|  en|RT @TheDemocrats:...|  TheRedPill333|\n",
      "|    1639926225|null|1472583437433323525|  en|RT @TheDemocrats:...|    Sailfish157|\n",
      "|    1639927086|null|1472587048003461122|  en|RT @SenWhitehouse...|      margpie55|\n",
      "|    1639926965|null|1472586539939078151|  en|@Sen_JoeManchin G...|        vdoogan|\n",
      "|    1639925718|null|1472581310698954753|  en|@SenatorRounds VO...|WalksWithEagles|\n",
      "|    1640621704|null|1475500488330260481|  en|@SenWhitehouse Th...|FreedricksonRio|\n",
      "|    1639925988|null|1472582444951945225|  en|@Sen_JoeManchin Y...| LoveCruising71|\n",
      "|    1639926504|null|1472584609669943298|  en|‚ÄúNow may the Lord...|   SenHydeSmith|\n",
      "|    1639925961|null|1472582331395362822|  en|@Sen_JoeManchin V...|    PurrdyPawws|\n",
      "|    1638057921|null|1464747203126341642|  en|@senrobportman  H...|      DanLees14|\n",
      "|    1639926046|null|1472582685470040068|  en|@votetimscott Ame...|      repmaidul|\n",
      "|    1640619995|null|1475493321648836608|  en|@POTUS You are ba...|TonaldD09930327|\n",
      "|    1639925817|null|1472581726614417413|  en|@Sen_JoeManchin i...|MelissaAlexVlog|\n",
      "|    1639924945|null|1472578067944071177|  en|@JoeBiden Sir, wi...|Patrici90785655|\n",
      "|    1639928674|null|1472593710957600768|  en|@SenWarren In Jap...| chevy_68impala|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lenght: 17686'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"/home/ubuntu/temp-data\")\n",
    "df.repartition(50).write.mode(\"overwrite\").parquet(\"/home/ubuntu/temp-data2\")\n",
    "df = spark.read.parquet(\"/home/ubuntu/temp-data2\")\n",
    "# df = spark.read.option(\"tableName\", \"tweets\").format(\"dynamodb\").load()\n",
    "df.show()\n",
    "f\"Lenght: {df.count()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308ca20",
   "metadata": {},
   "source": [
    "Removing special chacaters and changing to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c05c398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|extractionTime| geo|                 id|lang|                text|           user|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "|    1640622119|null|1475502230484697094|  en|     @potus         |      rodriQuez|\n",
      "|    1639923135|null|1472570476295860228| und|@vp @replowenthal...|  bandarfize1ap|\n",
      "|    1639923254|null|1472570974570795010|  en|@vp @allysonfelix...|   joshycharm01|\n",
      "|    1639927142|null|1472587285225156609|  en|@senjoemanchin wa...|        Caz_U_L|\n",
      "|    1640622154|null|1475502374982610946|  en|rt @housegop pres...|     CallMeBake|\n",
      "|    1639925917|null|1472582147638796293|  en|rt @thedemocrats ...|  TheRedPill333|\n",
      "|    1639926225|null|1472583437433323525|  en|rt @thedemocrats ...|    Sailfish157|\n",
      "|    1639927086|null|1472587048003461122|  en|rt @senwhitehouse...|      margpie55|\n",
      "|    1639926965|null|1472586539939078151|  en|@senjoemanchin ge...|        vdoogan|\n",
      "|    1639925718|null|1472581310698954753|  en|@senatorrounds vo...|WalksWithEagles|\n",
      "|    1640621704|null|1475500488330260481|  en|@senwhitehouse th...|FreedricksonRio|\n",
      "|    1639925988|null|1472582444951945225|  en|@senjoemanchin yo...| LoveCruising71|\n",
      "|    1639926504|null|1472584609669943298|  en|now may the lord ...|   SenHydeSmith|\n",
      "|    1639925961|null|1472582331395362822|  en|@senjoemanchin vo...|    PurrdyPawws|\n",
      "|    1638057921|null|1464747203126341642|  en|@senrobportman  h...|      DanLees14|\n",
      "|    1639926046|null|1472582685470040068|  en|@votetimscott ame...|      repmaidul|\n",
      "|    1640619995|null|1475493321648836608|  en|@potus you are ba...|TonaldD09930327|\n",
      "|    1639925817|null|1472581726614417413|  en|@senjoemanchin it...|MelissaAlexVlog|\n",
      "|    1639924945|null|1472578067944071177|  en|@joebiden sir wit...|Patrici90785655|\n",
      "|    1639928674|null|1472593710957600768|  en|@senwarren in jap...| chevy_68impala|\n",
      "+--------------+----+-------------------+----+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"text\", f.lower(f.regexp_replace(f.col(\"text\"), \"[^A-Za-z0-9@ ]\", \"\")))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13867c2a",
   "metadata": {},
   "source": [
    "# 2. LDA - topics analysis - Pyspark only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ece113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----+--------------------+-------------+--------------------+--------------------+\n",
      "|extractionTime| geo|                 id|lang|                text|         user|              tokens|       no stop words|\n",
      "+--------------+----+-------------------+----+--------------------+-------------+--------------------+--------------------+\n",
      "|    1640621115|null|1475498016417239041|  zh|             @potus |     xiga8806|            [@potus]|            [@potus]|\n",
      "|    1639926073|null|1472582800884879361|  en|@senjoemanchin th...|sabine_durden|[@senjoemanchin, ...|[@senjoemanchin, ...|\n",
      "|    1639924782|null|1472577386281463808|  en|@pattymurray @pat...|   ClydeKlotz|[@pattymurray, @p...|[@pattymurray, @p...|\n",
      "|    1640621860|null|1475501140762628103|  en|@barackobama the ...|      RACENKI|[@barackobama, th...|[@barackobama, ki...|\n",
      "|    1640622154|null|1475502374982610946|  en|rt @housegop pres...|   CallMeBake|[rt, @housegop, p...|[rt, @housegop, p...|\n",
      "+--------------+----+-------------------+----+--------------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'extractionTime': 1640621115,\n",
       "  'geo': None,\n",
       "  'id': 1475498016417239041,\n",
       "  'lang': 'zh',\n",
       "  'text': '@potus ',\n",
       "  'user': 'xiga8806',\n",
       "  'tokens': ['@potus'],\n",
       "  'no stop words': ['@potus']},\n",
       " {'extractionTime': 1639926073,\n",
       "  'geo': None,\n",
       "  'id': 1472582800884879361,\n",
       "  'lang': 'en',\n",
       "  'text': '@senjoemanchin thank you for standing against all the pressure and for doing whats right for americans ',\n",
       "  'user': 'sabine_durden',\n",
       "  'tokens': ['@senjoemanchin',\n",
       "   'thank',\n",
       "   'you',\n",
       "   'for',\n",
       "   'standing',\n",
       "   'against',\n",
       "   'all',\n",
       "   'the',\n",
       "   'pressure',\n",
       "   'and',\n",
       "   'for',\n",
       "   'doing',\n",
       "   'whats',\n",
       "   'right',\n",
       "   'for',\n",
       "   'americans'],\n",
       "  'no stop words': ['@senjoemanchin',\n",
       "   'thank',\n",
       "   'standing',\n",
       "   'pressure',\n",
       "   'whats',\n",
       "   'right',\n",
       "   'americans']},\n",
       " {'extractionTime': 1639924782,\n",
       "  'geo': None,\n",
       "  'id': 1472577386281463808,\n",
       "  'lang': 'en',\n",
       "  'text': '@pattymurray @pattymurray i dont see you riding horseback to washington dc oh wait thats right you httpstcojdvxtne7mk',\n",
       "  'user': 'ClydeKlotz',\n",
       "  'tokens': ['@pattymurray',\n",
       "   '@pattymurray',\n",
       "   'i',\n",
       "   'dont',\n",
       "   'see',\n",
       "   'you',\n",
       "   'riding',\n",
       "   'horseback',\n",
       "   'to',\n",
       "   'washington',\n",
       "   'dc',\n",
       "   'oh',\n",
       "   'wait',\n",
       "   'thats',\n",
       "   'right',\n",
       "   'you',\n",
       "   'httpstcojdvxtne7mk'],\n",
       "  'no stop words': ['@pattymurray',\n",
       "   '@pattymurray',\n",
       "   'dont',\n",
       "   'see',\n",
       "   'riding',\n",
       "   'horseback',\n",
       "   'washington',\n",
       "   'dc',\n",
       "   'oh',\n",
       "   'wait',\n",
       "   'thats',\n",
       "   'right',\n",
       "   'httpstcojdvxtne7mk']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = pysparkTokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopwords_cleaner = StopWordsRemover(inputCol=\"tokens\", outputCol=\"no stop words\")\n",
    "nlp_pipeline = Pipeline(\n",
    "    stages=[tokenizer,\n",
    "            stopwords_cleaner])\n",
    "nlp_model = nlp_pipeline.fit(df)\n",
    "processed_df  = nlp_model.transform(df)\n",
    "processed_df.show(5)\n",
    "processed_df.limit(3).toPandas().to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f0009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@potus', 'rt', 'money', 'americans', 'office', 'economy', 'took', 'pockets', 'brink', 'collapse', 'act', 'president', 'must', 'rights', '@thedemocrats'] \n",
      "\n",
      "['', '@senjoemanchin', '@potus', 'manchin', 'joe', '@senschumer', 'vote', 'rt', 'state', '@vp', '@kamalaharris', 'million', 'bbb', 'plan', '@joemanchinwv'] \n",
      "\n",
      "['@potus', '@joebiden', '@tedcruz', 'rt', 'get', 'back', '@lindseygrahamsc', 'us', '@kamalaharris', 'dont', 'like', 'going', 'better', 'people', 'build'] \n",
      "\n",
      "['', 'rt', '@tedcruz', 'party', 'democrat', 'mask', 'must', 'one', '@amyklobuchar', 'wear', 'want', 'forever', 'official', 'positioneverybody', 'better'] \n",
      "\n",
      "['@senjoemanchin', 'people', 'rt', '@senwarren', 'american', 'youre', 'know', 'thats', 'bill', 'thank', 'republican', 'democrats', 'tax', 'care', 'bbb'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"no stop words\", outputCol=\"features\", vocabSize=500, minDF=3.0)\n",
    "cv_model = cv.fit(processed_df)\n",
    "lda = LDA(k=5, maxIter=100)\n",
    "model = lda.fit(cv_model.transform(processed_df))\n",
    "for indices in model.describeTopics(15).select(\"termIndices\").rdd.flatMap(lambda x: x).collect():\n",
    "    print([cv_model.vocabulary[i] for i in indices], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00101ca",
   "metadata": {},
   "source": [
    "# 3. LDA - topics analysis - SparkNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00280e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1212, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39585)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-b7842127e95e>\", line 19, in <module>\n",
      "    processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/pipeline.py\", line 112, in _fit\n",
      "    dataset = stage.transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 217, in transform\n",
      "    return self._transform(dataset)\n",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 350, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o105.transform\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o105.transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b7842127e95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  \u001b[0mchunker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                  finisher])\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprocessed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished_unigrams\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"finished_ngrams\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprocessed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o105.transform"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol('document')\n",
    "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('tokenized')\n",
    "normalizer = Normalizer().setInputCols(['tokenized']).setOutputCol('normalized')\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols(['normalized']).setOutputCol('lemmatized')\n",
    "stopwords_cleaner = StopWordsCleaner().setInputCols(['lemmatized'])\\\n",
    ".setOutputCol('unigrams').setStopWords(stopwords.words('english'))\n",
    "pos_tagger = PerceptronModel.pretrained('pos_anc').setInputCols(['document', 'unigrams']).setOutputCol('pos')\n",
    "chunker = Chunker().setInputCols(['document', 'pos']).setOutputCol('ngrams').setRegexParsers(['<JJ>+<NN>', '<NN>+<NN>'])\n",
    "finisher = Finisher().setInputCols(['unigrams', 'ngrams'])\n",
    "pipeline = Pipeline() \\\n",
    "     .setStages([documentAssembler,\n",
    "                 tokenizer,\n",
    "                 normalizer,\n",
    "                 lemmatizer,\n",
    "                 stopwords_cleaner,\n",
    "                 pos_tagger,\n",
    "                 chunker,\n",
    "                 finisher])\n",
    "processed_df = pipeline.fit(df).transform(df).withColumn(\"final\", f.concat(\"finished_unigrams\", \"finished_ngrams\"))\n",
    "processed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24050e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"final\", outputCol=\"features\", vocabSize=500, minDF=3.0)\n",
    "cv_model = cv.fit(processed_df)\n",
    "lda = LDA(k=5, maxIter=100)\n",
    "model = lda.fit(cv_model.transform(processed_df))\n",
    "for indices in model.describeTopics(15).select(\"termIndices\").rdd.flatMap(lambda x: x).collect():\n",
    "    print([cv_model.vocabulary[i] for i in indices], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356aa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
