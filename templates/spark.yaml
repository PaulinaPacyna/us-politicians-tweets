AWSTemplateFormatVersion: 2010-09-09
# Resources
Resources:
  SparkInstance:
    Type: 'AWS::EC2::Instance'
    Properties:
      InstanceType: 't2.small'
      SecurityGroupIds:
        - !Ref SparkInstanceSecurityGroup
      IamInstanceProfile: !Ref SparkInstanceProfile
      KeyName: 'nifi'
      ImageId: 'ami-0747bdcabd34c712a'
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -xe
          sudo su
          exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1
          apt-get update -y
          sudo apt install default-jdk scala git python3-pip -y
          cd ~
          wget https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
          tar xvf spark-*
          sudo mv spark-3.1.2-bin-hadoop2.7 /opt/spark
          echo "PATH=\"$PATH:/opt/spark/sbin:/opt/spark/bin\"" >> /home/ubuntu/.profile
          source /home/ubuntu/.profile
          /opt/spark/sbin/start-master.sh
          sudo apt install python3-pip
          pip3 install notebook
          export PYSPARK_DRIVER_PYTHON='jupyter'
          export PYSPARK_DRIVER_PYTHON_OPTS='notebook --allow-root --no-browser --port=8888'
          jupyter notebook --generate-config -y
          echo "conf = get_config()" >> /root/.jupyter/jupyter_notebook_config.py
          echo "conf.NotebookApp.ip = '0.0.0.0'">> /root/.jupyter/jupyter_notebook_config.py
          echo "conf.NotebookApp.port = 8888" >> /root/.jupyter/jupyter_notebook_config.py
          wget https://raw.githubusercontent.com/tryptofanik/us-politicians-tweets/spark/spark/set_jupyter_passwd.py
          ipython set_jupyter_passwd.py
          rm set_jupyter_passwd.py
          mkdir /spark-workspace
          cd /spark-workspace
          wget http://snap.stanford.edu/data/redditSubmissions.csv.gz
          wget https://raw.githubusercontent.com/tryptofanik/us-politicians-tweets/spark/spark/example.ipynb
          wget https://raw.githubusercontent.com/tryptofanik/us-politicians-tweets/spark/spark/EDA.ipynb
          /opt/spark/bin/pyspark --packages com.audienceproject:spark-dynamodb_2.12:1.1.1 > error.log &

  SparkInstanceSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: Group for Spark instance
      SecurityGroupIngress:
        - IpProtocol: tcp
          ToPort: '8080'
          FromPort: '8080'
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          ToPort: '4040'
          FromPort: '4040'
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          ToPort: '8888'
          FromPort: '8888'
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          ToPort: '4040'
          FromPort: '4040'
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          ToPort: '22'
          FromPort: '22'
          CidrIp: 0.0.0.0/0

  SparkInstanceProfile:
    Type: 'AWS::IAM::InstanceProfile'
    Properties:
      Path: /
      Roles:
        - !Ref SparkRole

  SparkRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: SparkRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
  RunEC2Policy:
    Type: 'AWS::IAM::Policy'
    Properties:
      PolicyName: RunEC2Policy
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          Effect: Allow
          Action:
            - 'ec2:RunInstances'
            - 'ec2:AttachVolume'
            - 'ec2:CreateVolume'
            - 'ec2:CreateSecurityGroup'
          Resource: '*'
      Roles:
        - !Ref SparkRole

  ReadWriteDynamoDB:
    Type: 'AWS::IAM::Policy'
    Properties:
      PolicyName: ReadWriteDynamoDB
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          Effect: Allow
          Action:
            - 'dynamodb:CreateTable'
            - 'dynamodb:PutItem'
            - 'dynamodb:DescribeTable'
            - 'dynamodb:DeleteItem'
            - 'dynamodb:GetItem'
            - 'dynamodb:Scan'
            - 'dynamodb:Query'
          Resource: 'arn:aws:dynamodb:*:297252523626:table/*'
      Roles:
        - !Ref SparkRole
Outputs:
  IP:
    Description: IP
    Value: !Sub "ubuntu@${SparkInstance.PublicIp}"
  SparkUI:
    Description: Spark UI
    Value: !Sub "http://${SparkInstance.PublicIp}:8080"
  Jupyter:
    Description: Link to jupyter notebook with spark installed
    Value: !Sub "http://${SparkInstance.PublicIp}:8888"
#  ReadDynamoDBPolicy:
#    Type: 'AWS::IAM::Policy'
#    DependsOn: TweetsDynamoDBTable
#    Properties:
#      PolicyName: ReadTweetsPolicy
#      PolicyDocument:
#        Version: 2012-10-17
#        Statement:
#          Effect: Allow
#          Action:
#            - 'dynamodb:Scan'
#            - 'dynamodb:Describe*'
#            - 'dynamodb:Get*'
#            - 'dynamodb:Query'
#            - 'dynamodb:List*'
#          Resource: "*"
#      Roles:
#        - !Ref SparkRole